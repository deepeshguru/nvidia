{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from tensorflow.python.platform import gfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0911 10:08:30.312613 140552366577472 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "x = base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x)\n",
    "x=Dropout(0.5)(x)\n",
    "preds=Dense(1,activation='sigmoid')(x) #final layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "  layer.trinable=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_data = datagen.flow_from_directory(directory='chest_xray/train', \n",
    "                                         target_size=(299, 299), \n",
    "                                         color_mode='rgb', \n",
    "                                         class_mode='binary', \n",
    "                                         batch_size=32, \n",
    "                                         shuffle=True)\n",
    "val_data = datagen.flow_from_directory(directory='chest_xray/test', \n",
    "                                         target_size=(299, 299), \n",
    "                                         color_mode='rgb', \n",
    "                                         class_mode='binary', \n",
    "                                         batch_size=32, \n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 10:08:49.199019 140552366577472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "163/163 [==============================] - 148s 907ms/step - loss: 0.1329 - acc: 0.9546 - val_loss: 4.8987 - val_acc: 0.8339\n",
      "Epoch 2/2\n",
      "163/163 [==============================] - 110s 675ms/step - loss: 0.0552 - acc: 0.9804 - val_loss: 0.5833 - val_acc: 0.8553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd3c9935898>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_train = train_data.n // train_data.batch_size\n",
    "step_val = val_data.n // val_data.batch_size\n",
    "\n",
    "model.fit_generator(generator=train_data, \n",
    "                    shuffle=True, \n",
    "                    steps_per_epoch=step_train, \n",
    "                    epochs=2, \n",
    "                    validation_data=val_data, \n",
    "                    validation_steps=step_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('chest_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/Sigmoid:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-247594eb9b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                               \u001b[0;34m\"save/restore_all\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"save/Const:0\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                               models_dir+model_filename, False, \"\")\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mconvert_keras_to_pb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chest_model.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'dense_1/Sigmoid:0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chest_model.pb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-247594eb9b86>\u001b[0m in \u001b[0;36mconvert_keras_to_pb\u001b[0;34m(keras_model, out_names, models_dir, model_filename)\u001b[0m\n\u001b[1;32m     17\u001b[0m                               \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                               \u001b[0;34m\"save/restore_all\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"save/Const:0\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                               models_dir+model_filename, False, \"\")\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mconvert_keras_to_pb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chest_model.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'dense_1/Sigmoid:0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chest_model.pb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py\u001b[0m in \u001b[0;36mfreeze_graph\u001b[0;34m(input_graph, input_saver, input_binary, input_checkpoint, output_node_names, restore_op_name, filename_tensor_name, output_graph, clear_devices, initializer_nodes, variable_names_whitelist, variable_names_blacklist, input_meta_graph, input_saved_model_dir, saved_model_tags, checkpoint_version)\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0minput_saved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0msaved_model_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m       checkpoint_version=checkpoint_version)\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py\u001b[0m in \u001b[0;36mfreeze_graph_with_def_protos\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    188\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         saver = saver_lib.Saver(\n\u001b[0;32m--> 190\u001b[0;31m             var_list=var_list, write_version=checkpoint_version)\n\u001b[0m\u001b[1;32m    191\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# `var_list` is required to be a map of variable names to Variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m    823\u001b[0m           time.time() + self._keep_checkpoint_every_n_hours * 3600)\n\u001b[1;32m    824\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m    873\u001b[0m           \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m           build_restore=build_restore)\n\u001b[0m\u001b[1;32m    876\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build_internal\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename, build_save, build_restore)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     saveables = saveable_object_util.validate_and_slice_inputs(\n\u001b[0;32m--> 482\u001b[0;31m         names_to_saveables)\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_to_keep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m       \u001b[0mmax_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36mvalidate_and_slice_inputs\u001b[0;34m(names_to_saveables)\u001b[0m\n\u001b[1;32m    340\u001b[0m                          \u001b[0;31m# Avoid comparing ops, sort only by name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                          key=lambda x: x[0]):\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mconverted_saveable_object\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msaveable_objects_for_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0m_add_saveable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseen_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_saveable_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msaveables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36msaveable_objects_for_op\u001b[0;34m(op, name)\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         yield ResourceVariableSaveable(\n\u001b[0;32m--> 205\u001b[0;31m             variable, \"\", name)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var, slice_spec, name)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m       \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mresource_variable_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_resource_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "from tensorflow.python.training import saver as saver_lib\n",
    "\n",
    "def convert_keras_to_pb(keras_model, out_names, models_dir, model_filename):\n",
    "    model = load_model(keras_model)\n",
    "    K.set_learning_phase(0)\n",
    "    sess = K.get_session()\n",
    "    saver = saver_lib.Saver(write_version=saver_pb2.SaverDef.V2)\n",
    "    checkpoint_path = saver.save(sess, 'saved_ckpt', global_step=0, latest_filename='checkpoint_state')\n",
    "    graph_io.write_graph(sess.graph, '.', 'tmp.pb')\n",
    "    freeze_graph.freeze_graph('./tmp.pb', \n",
    "                              '',\n",
    "                              False, checkpoint_path, out_names,\n",
    "                              \"save/restore_all\", \"save/Const:0\",\n",
    "                              models_dir+model_filename, False, \"\")\n",
    "convert_keras_to_pb(\"chest_model.h5\", ['dense_1/Sigmoid'], '', 'chest_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "# This line must be executed before loading Keras model.\n",
    "K.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0911 10:33:23.140794 140077484074816 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0911 10:33:23.142192 140077484074816 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0911 10:33:23.143296 140077484074816 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0911 10:33:23.148699 140077484074816 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0911 10:33:36.724878 140077484074816 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'dense_1/Sigmoid:0' shape=(?, 1) dtype=float32>]\n",
      "[<tf.Tensor 'input_1:0' shape=(?, 299, 299, 3) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('chest_model.h5')\n",
    "print(model.outputs)\n",
    "# [<tf.Tensor 'dense_2/Softmax:0' shape=(?, 10) dtype=float32>]\n",
    "print(model.inputs)\n",
    "# [<tf.Tensor 'conv2d_1_input:0' shape=(?, 28, 28, 1) dtype=float32>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 10:33:54.683955 140077484074816 deprecation.py:323] From <ipython-input-8-e018fe30fb29>:28: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W0911 10:33:54.684833 140077484074816 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    }
   ],
   "source": [
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        # Graph -> GraphDef ProtoBuf\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph\n",
    "\n",
    "\n",
    "frozen_graph = freeze_session(K.get_session(),\n",
    "                              output_names=[out.op.name for out in model.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chest_model.h5',\n",
       " 'Untitled.ipynb',\n",
       " 'tmp.pb',\n",
       " 'checkpoint_state',\n",
       " '__MACOSX',\n",
       " 'chest_xray',\n",
       " 'saved_ckpt-0.index',\n",
       " '.ipynb_checkpoints',\n",
       " 'saved_ckpt-0.data-00000-of-00001',\n",
       " 'saved_ckpt-0.meta',\n",
       " 'chest_model.pb']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save to ./model/tf_model.pb\n",
    "tf.train.write_graph(frozen_graph, \"\", \"chest_model.pb\", as_text=False)\n",
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 11:28:17.856310 140077484074816 deprecation.py:323] From <ipython-input-18-0225cca0ef9b>:10: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT model is successfully stored!\n"
     ]
    }
   ],
   "source": [
    "# convert (optimize) frozen model to TensorRT model\n",
    "trt_graph = trt.create_inference_graph(\n",
    "    input_graph_def=frozen_graph,# frozen model\n",
    "    outputs=['dense_1/Sigmoid'],\n",
    "    max_batch_size=64,# specify your max batch size\n",
    "    max_workspace_size_bytes=2*(10**9),# specify the max workspace\n",
    "    precision_mode=\"FP16\") # precision, can be \"FP32\" (32 floating point precision) or \"FP16\"\n",
    "\n",
    "#write the TensorRT model to be used later for inference\n",
    "with gfile.FastGFile(\"chest_TensorRT_model.pb\", 'wb') as f:\n",
    "    f.write(trt_graph.SerializeToString())\n",
    "print(\"TensorRT model is successfully stored!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the needed libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.tensorrt as trt # must import this although we will not use it explicitly\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "\n",
    "img1 = image.load_img(r'chest_xray/val/NORMAL/' + 'NORMAL2-IM-1438-0001.jpeg', target_size=(299, 299))\n",
    "img_array1 = image.img_to_array(img1)\n",
    "img_array_expanded_dims1 = np.expand_dims(img_array1, axis=0)\n",
    "img1 = preprocess_input(img_array_expanded_dims1)\n",
    "\n",
    "img2 = image.load_img('chest_xray/val/NORMAL/' + 'NORMAL2-IM-1440-0001.jpeg', target_size=(299, 299))\n",
    "img_array2 = image.img_to_array(img2)\n",
    "img_array_expanded_dims2 = np.expand_dims(img_array2, axis=0)\n",
    "img2 = preprocess_input(img_array_expanded_dims2)\n",
    "\n",
    "input_img = np.concatenate((img1, img2),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 299, 299, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read a \".pb\" model \n",
    "# (can be used to read frozen model or TensorRT model)\n",
    "import time\n",
    "def read_pb_graph(model):\n",
    "  with gfile.FastGFile(model,'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "  return graph_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "needed time in inference-0:  0.010419130325317383\n",
      "needed time in inference-1:  0.010721445083618164\n",
      "needed time in inference-2:  0.011287927627563477\n",
      "needed time in inference-3:  0.01136159896850586\n",
      "needed time in inference-4:  0.010973453521728516\n",
      "needed time in inference-5:  0.011221170425415039\n",
      "needed time in inference-6:  0.010986566543579102\n",
      "needed time in inference-7:  0.0097198486328125\n",
      "needed time in inference-8:  0.01002359390258789\n",
      "needed time in inference-9:  0.010281562805175781\n",
      "needed time in inference-10:  0.009742021560668945\n",
      "needed time in inference-11:  0.010100364685058594\n",
      "needed time in inference-12:  0.010137796401977539\n",
      "needed time in inference-13:  0.010174989700317383\n",
      "needed time in inference-14:  0.009631156921386719\n",
      "needed time in inference-15:  0.010051727294921875\n",
      "needed time in inference-16:  0.010152578353881836\n",
      "needed time in inference-17:  0.009802579879760742\n",
      "needed time in inference-18:  0.009966373443603516\n",
      "needed time in inference-19:  0.010402441024780273\n",
      "needed time in inference-20:  0.010405778884887695\n",
      "needed time in inference-21:  0.009778022766113281\n",
      "needed time in inference-22:  0.00981450080871582\n",
      "needed time in inference-23:  0.009748458862304688\n",
      "needed time in inference-24:  0.00949549674987793\n",
      "needed time in inference-25:  0.009311914443969727\n",
      "needed time in inference-26:  0.009702682495117188\n",
      "needed time in inference-27:  0.009695291519165039\n",
      "needed time in inference-28:  0.009517192840576172\n",
      "needed time in inference-29:  0.009348154067993164\n",
      "needed time in inference-30:  0.009781599044799805\n",
      "needed time in inference-31:  0.009328603744506836\n",
      "needed time in inference-32:  0.00983119010925293\n",
      "needed time in inference-33:  0.009261131286621094\n",
      "needed time in inference-34:  0.009638071060180664\n",
      "needed time in inference-35:  0.009651660919189453\n",
      "needed time in inference-36:  0.009124517440795898\n",
      "needed time in inference-37:  0.009607076644897461\n",
      "needed time in inference-38:  0.009531736373901367\n",
      "needed time in inference-39:  0.009574413299560547\n",
      "needed time in inference-40:  0.009528160095214844\n",
      "needed time in inference-41:  0.008929729461669922\n",
      "needed time in inference-42:  0.009594440460205078\n",
      "needed time in inference-43:  0.009584903717041016\n",
      "needed time in inference-44:  0.009557723999023438\n",
      "needed time in inference-45:  0.009267091751098633\n",
      "needed time in inference-46:  0.00894618034362793\n",
      "needed time in inference-47:  0.009561538696289062\n",
      "needed time in inference-48:  0.00870203971862793\n",
      "needed time in inference-49:  0.009447336196899414\n",
      "average inference time:  0.009848499298095703\n"
     ]
    }
   ],
   "source": [
    "# variable\n",
    "TENSORRT_MODEL_PATH = 'chest_TensorRT_model.pb'\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.50))) as sess:\n",
    "        # read TensorRT model\n",
    "        trt_graph = read_pb_graph(TENSORRT_MODEL_PATH)\n",
    "\n",
    "        # obtain the corresponding input-output tensor\n",
    "        tf.import_graph_def(trt_graph, name='')\n",
    "        input = sess.graph.get_tensor_by_name('input_1:0')\n",
    "        output = sess.graph.get_tensor_by_name('dense_1/Sigmoid:0')\n",
    "\n",
    "        # in this case, it demonstrates to perform inference for 50 times\n",
    "        total_time = 0; n_time_inference = 50\n",
    "        out_pred = sess.run(output, feed_dict={input: input_img})\n",
    "        for i in range(n_time_inference):\n",
    "            t1 = time.time()\n",
    "            out_pred = sess.run(output, feed_dict={input: input_img})\n",
    "            t2 = time.time()\n",
    "            delta_time = t2 - t1\n",
    "            total_time += delta_time\n",
    "            print(\"needed time in inference-\" + str(i) + \": \", delta_time)\n",
    "        avg_time_tensorRT = total_time / n_time_inference\n",
    "        print(\"average inference time: \", avg_time_tensorRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "needed time in inference-0:  0.21779942512512207\n",
      "needed time in inference-1:  0.02843642234802246\n",
      "needed time in inference-2:  0.030545711517333984\n",
      "needed time in inference-3:  0.026583433151245117\n",
      "needed time in inference-4:  0.026366233825683594\n",
      "needed time in inference-5:  0.023306846618652344\n",
      "needed time in inference-6:  0.025398969650268555\n",
      "needed time in inference-7:  0.0233309268951416\n",
      "needed time in inference-8:  0.02337360382080078\n",
      "needed time in inference-9:  0.023790597915649414\n",
      "needed time in inference-10:  0.030689239501953125\n",
      "needed time in inference-11:  0.022977828979492188\n",
      "needed time in inference-12:  0.028777360916137695\n",
      "needed time in inference-13:  0.02548813819885254\n",
      "needed time in inference-14:  0.02433300018310547\n",
      "needed time in inference-15:  0.022630929946899414\n",
      "needed time in inference-16:  0.027002334594726562\n",
      "needed time in inference-17:  0.024901390075683594\n",
      "needed time in inference-18:  0.023601055145263672\n",
      "needed time in inference-19:  0.026021957397460938\n",
      "needed time in inference-20:  0.023480892181396484\n",
      "needed time in inference-21:  0.024631738662719727\n",
      "needed time in inference-22:  0.02462291717529297\n",
      "needed time in inference-23:  0.026752233505249023\n",
      "needed time in inference-24:  0.023396730422973633\n",
      "needed time in inference-25:  0.023962736129760742\n",
      "needed time in inference-26:  0.02410292625427246\n",
      "needed time in inference-27:  0.02236175537109375\n",
      "needed time in inference-28:  0.022792339324951172\n",
      "needed time in inference-29:  0.022377490997314453\n",
      "needed time in inference-30:  0.022243738174438477\n",
      "needed time in inference-31:  0.02294015884399414\n",
      "needed time in inference-32:  0.023863554000854492\n",
      "needed time in inference-33:  0.022700786590576172\n",
      "needed time in inference-34:  0.022816896438598633\n",
      "needed time in inference-35:  0.02498602867126465\n",
      "needed time in inference-36:  0.024994611740112305\n",
      "needed time in inference-37:  0.022578954696655273\n",
      "needed time in inference-38:  0.0224764347076416\n",
      "needed time in inference-39:  0.025469064712524414\n",
      "needed time in inference-40:  0.023742198944091797\n",
      "needed time in inference-41:  0.023053646087646484\n",
      "needed time in inference-42:  0.023506879806518555\n",
      "needed time in inference-43:  0.02473926544189453\n",
      "needed time in inference-44:  0.028496742248535156\n",
      "needed time in inference-45:  0.0255889892578125\n",
      "needed time in inference-46:  0.02250814437866211\n",
      "needed time in inference-47:  0.02701568603515625\n",
      "needed time in inference-48:  0.02573394775390625\n",
      "needed time in inference-49:  0.022787809371948242\n",
      "average inference time:  0.028521614074707033\n",
      "TensorRT improvement compared to the original model: 2.896036564699959\n"
     ]
    }
   ],
   "source": [
    "# variable\n",
    "FROZEN_MODEL_PATH = 'chest_model.pb'\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        # read TensorRT model\n",
    "        frozen_graph = read_pb_graph(FROZEN_MODEL_PATH)\n",
    "\n",
    "        # obtain the corresponding input-output tensor\n",
    "        tf.import_graph_def(frozen_graph, name='')\n",
    "        input = sess.graph.get_tensor_by_name('input_1:0')\n",
    "        output = sess.graph.get_tensor_by_name('dense_1/Sigmoid:0')\n",
    "\n",
    "        # in this case, it demonstrates to perform inference for 50 times\n",
    "        total_time = 0; n_time_inference = 50\n",
    "        out_pred = sess.run(output, feed_dict={input: input_img})\n",
    "        for i in range(n_time_inference):\n",
    "            t1 = time.time()\n",
    "            out_pred = sess.run(output, feed_dict={input: input_img})\n",
    "            t2 = time.time()\n",
    "            delta_time = t2 - t1\n",
    "            total_time += delta_time\n",
    "            print(\"needed time in inference-\" + str(i) + \": \", delta_time)\n",
    "        avg_time_original_model = total_time / n_time_inference\n",
    "        print(\"average inference time: \", avg_time_original_model)\n",
    "        print(\"TensorRT improvement compared to the original model:\", avg_time_original_model/avg_time_tensorRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
